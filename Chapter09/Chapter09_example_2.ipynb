{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "680d8e4b-75c1-4a36-8c0e-da57008ce21b",
   "metadata": {},
   "source": [
    "### Extract data from SiteMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32767cbd-3954-4bf4-b5b7-75a38f2eac4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7ec033-860d-4251-8140-41921a7cd0fc",
   "metadata": {},
   "source": [
    "#### List, url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00ee814-4cc3-4232-8bdf-302dfe34d766",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet=[]  #Collectors\n",
    "dataJSON=[]\n",
    "\n",
    "columns = ['Site','Type','Topic','Date','Time'] # Header Row\n",
    "title=\"Content Zyte\"  #fileName\n",
    "\n",
    "url=\"https://www.zyte.com/post-sitemap.xml\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7684534-66aa-4d87-b4fd-353dee2a515b",
   "metadata": {},
   "source": [
    "#### Load the url and receive the content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fda54b35-74c1-44de-b6ef-aa5fbfc7d005",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = requests.get(url).text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d462e72-a3c3-4964-b54e-1eae1bb1228d",
   "metadata": {},
   "source": [
    "#### Content sample"
   ]
  },
  {
   "cell_type": "raw",
   "id": "33de1f87-a63e-4999-9ac7-bb069ec073fd",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "\t<url>\n",
    "\t\t<loc>https://www.zyte.com/blog/json-parsing-with-python/</loc>\n",
    "\t\t<lastmod>2023-04-06T14:42:05+00:00</lastmod>\n",
    "\t</url>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa996b6-6554-4434-99f2-ad7538a4a697",
   "metadata": {},
   "source": [
    "#### Regex & logical steps to collect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6271d1f4-edf3-4be8-b4f6-9d9db2c8b345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is available\n",
      "['https://www.zyte.com/blog/json-parsing-with-python/', 'https://www.zyte.com/blog/scraping-e-commerce-websites-product-data-at-scale/']\n",
      "['2023-04-06T14:42:05+00:00', '2023-04-06T14:39:47+00:00']\n",
      "Total locs 352\n",
      "Total locFinals 352\n"
     ]
    }
   ],
   "source": [
    "if re.search(r\"\\<loc\\>\",source):\n",
    "    print(\"Data is available\")\n",
    "    \n",
    "    locs = re.findall(r\"\\<loc\\>(.*)\\<\\/loc\\>\",source)\n",
    "    mods = re.findall(r\"mod\\>(.*)\\<\\/last\",source)\n",
    "    print(locs[0:2]) #sample\n",
    "    print(mods[0:2]) #sample\n",
    "    \n",
    "    if len(locs)==len(mods):\n",
    "        print(f\"Total locs {len(locs)}\")\n",
    "        \n",
    "        locFinals = list(zip(locs,mods))   #zip\n",
    "        print(f\"Total locFinals {len(locFinals)}\")\n",
    "        \n",
    "        for locFinal in locFinals:\n",
    "            loc,datetime=locFinal\n",
    "            \n",
    "            loc = re.sub('^(http\\:|https\\:)','',loc)\n",
    "            loc = re.sub('[\\/]{2}','',loc)\n",
    "            loc = re.sub('\\/$','',loc)\n",
    "            \n",
    "            locSplit=re.split(r\"\\/\",loc)\n",
    "            category=locSplit[1]\n",
    "            categoryTopic=re.sub('\\-',' ',locSplit[2])\n",
    "            \n",
    "            ymdTime = re.split(\"T\",datetime)\n",
    "            ymd = ymdTime[0]\n",
    "            time = re.sub(\"\\+.*\",\"\",ymdTime[1])\n",
    "            \n",
    "            dataSet.append([\"Zyte\",category,categoryTopic,ymd,time])           \n",
    "            dataJSON.append({\"site\":\"Zyte\",\"type\":category,\"topic\":categoryTopic,\"date\":ymd,\"time\":time})       \n",
    "else:\n",
    "    print(\"Dealer Data is not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a5e365-8ac8-42c0-8ab9-d8c655a665ec",
   "metadata": {},
   "source": [
    "#### Sample of collected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ca0279d-b99b-49e5-80a3-54c79f8f7bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Zyte', 'blog', 'json parsing with python', '2023-04-06', '14:42:05'],\n",
       " ['Zyte',\n",
       "  'blog',\n",
       "  'scraping e commerce websites product data at scale',\n",
       "  '2023-04-06',\n",
       "  '14:39:47'],\n",
       " ['Zyte',\n",
       "  'blog',\n",
       "  'how to safely extract data from social media platforms and news sites',\n",
       "  '2023-03-31',\n",
       "  '05:28:01'],\n",
       " ['Zyte',\n",
       "  'uncategorized',\n",
       "  'do you have the right data fields for your e commerce data project',\n",
       "  '2023-03-30',\n",
       "  '06:34:37'],\n",
       " ['Zyte',\n",
       "  'webinars',\n",
       "  'how to launch a large scale web data extraction project',\n",
       "  '2023-03-30',\n",
       "  '05:55:38'],\n",
       " ['Zyte',\n",
       "  'blog',\n",
       "  'importance web scraping data journalism',\n",
       "  '2023-03-29',\n",
       "  '17:59:08'],\n",
       " ['Zyte',\n",
       "  'blog',\n",
       "  'challenges enterprise ecommerce web scraping proxies',\n",
       "  '2023-03-21',\n",
       "  '07:27:56'],\n",
       " ['Zyte',\n",
       "  'blog',\n",
       "  'how web data can fuel your dynamic pricing strategy',\n",
       "  '2023-03-21',\n",
       "  '06:53:53'],\n",
       " ['Zyte', 'blog', 'scraping customer reviews', '2023-03-21', '06:29:51'],\n",
       " ['Zyte',\n",
       "  'webinars',\n",
       "  'the right data fields for e commerce data project',\n",
       "  '2023-03-21',\n",
       "  '06:17:35']]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataSet[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0864ff-b318-45c1-8f5c-78b222b938e3",
   "metadata": {},
   "source": [
    "#### Export data to JSON and CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20a6ce75-9541-4962-879c-0afebee20cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(title.replace(\" \",\"-\")+\".json\", \"w\") as file:\n",
    "    json.dump(dataJSON, file, indent=4, sort_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71b71d9a-7839-4e00-b8d4-c61cdbc88c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a04fc012-f179-44b7-a4dd-88b085b25623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeto_csv(data,filename,columns):\n",
    "    with open(filename,'w+',newline='',encoding=\"UTF-8\") as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=columns)\n",
    "        writer.writeheader()\n",
    "        writer = csv.writer(file)\n",
    "        for element in data:\n",
    "            writer.writerows([element])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0bda833f-8838-4e1e-bfbd-de4afc25f255",
   "metadata": {},
   "outputs": [],
   "source": [
    "writeto_csv(dataSet,title.replace(\" \",\"-\")+\".csv\",columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81588ba-7b4f-4f5c-8893-2b72cafd3d05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
